{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b77127-711a-48af-a06a-8f1be577cfae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from threading import Thread\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer, BitsAndBytesConfig\n",
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852d48cc-6036-4733-b244-d60941cbdc51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff0fdc6f410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493af12b-c82b-43e0-ace4-8ff6ef3f6996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import log, prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2e5ea4-588b-4edd-bd6d-3558489efd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del Retriever\n",
    "from contriever import Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6298c7c-c4cd-41b7-8544-c069ad331b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path='mydata-chatbot.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f133d5a-2fde-4606-9962-f2187cd8a6f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EosLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self):\n",
    "        self.stop_rate = None\n",
    "        self.newline_id = 13\n",
    "        self.eos_id = 2\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        if scores[0].argmax().item() != self.newline_id and self.stop_rate is None:\n",
    "            self.stop_rate = 1.0\n",
    "        if self.stop_rate is not None:\n",
    "            if scores[0].argmax().item() == self.newline_id:\n",
    "                self.stop_rate *= 1.1\n",
    "            scores[:, self.eos_id] = scores[:, self.eos_id] * self.stop_rate\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ca1039-7f09-47b9-baab-9fab65e8dab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CudaModel:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.load_model()\n",
    "        self.logits_processor = LogitsProcessorList()\n",
    "        self.logits_processor.append(EosLogitsProcessor())\n",
    "\n",
    "    def load_model(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_path, model_max_length=8192)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=False,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "        print('Loading model ...')\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_path,\n",
    "            quantization_config=bnb_config,\n",
    "            use_cache=True,\n",
    "            # do_sample=True,\n",
    "            device_map='auto'\n",
    "        )\n",
    "        return model, tokenizer\n",
    "\n",
    "    def gen_output(self, input, text):\n",
    "        prompt = prompt_template % (text, input)\n",
    "        log.info('Tokenizing ...')\n",
    "        input_ids = self.tokenizer([prompt], return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "        streamer = TextIteratorStreamer(self.tokenizer, skip_prompt=True)\n",
    "        generation_kwargs = dict(\n",
    "            input_ids,\n",
    "            streamer=streamer,\n",
    "            logits_processor=self.logits_processor,\n",
    "            max_new_tokens=500,\n",
    "            do_sample=False,\n",
    "            # top_p=0.9,\n",
    "            # temperature=0.1\n",
    "        )\n",
    "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "        for outp in streamer:\n",
    "            yield outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2bcb385-0485-44f2-b007-90f41c02dc02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a190963d6aab4ca28d0ea6e9715b069b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CudaModel(os.getenv('CHAT_MODEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea7be53-f462-42d2-ac8e-68f5c9f862d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.py:Loading embedding model /home/cdsw/models/all-mpnet-base-v2 ... \n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: /home/cdsw/models/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "retriever = Retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f4b4571-d1f6-4913-8af1-4ade9963d2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_en = 'Do you have the revenue information of Cloudera in 2019?'\n",
    "text_id = 'Berapa pendapatan Cloudera pada tahun 2019?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11346d5f-1b7b-409a-b9a8-6e44c17d2da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13fc8128e6548b18893e53757bf5e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64230 0.651945531 BRIEF-Seven Stars Cloud Group Sees FY 2017 Revenue $125 Mln To $144 Mln\n",
      "February 23, 2018 / 2:05 PM / in 9 minutes BRIEF-Seven Stars Cloud Group Sees FY 2017 Revenue $125 M\n",
      "==============================\n",
      "68315 0.617973 BRIEF-Coima Res Profit For The Period At End-2017 Of EUR 28.9 Million\n",
      "Feb 22 (Reuters) - Coima Res Spa Siiq:\n",
      "* PROFIT FOR THE PERIOD AT END-2017 OF EUR 28.9 MILLION\n",
      "* SAY\n",
      "==============================\n",
      "29373 0.615841448 Cegedim: Release of Full-Year 2017 Revenue\n",
      "Press Release Full year Financial Information at December 31, 2017\n",
      "IFRS - Regulated Information - No\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "texts = retriever.get_texts(text_en, top_k=3)\n",
    "for id, title, text, score in texts:\n",
    "    print(id, score, title)\n",
    "    print(text[:100])\n",
    "    print('=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23c391e3-fd68-4eb9-9f3a-d45b59487166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cegedim: Release of Full-Year 2017 Revenue \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Press Release Full year Financial Information at December 31, 2017\\nIFRS - Regulated Information - Not Audited\\nCegedim: organic growth accelerated in 2017\\nRevenues grew 5.9% like for like over the full year Outlook for consolidated 2017 EBITDA raised significantly Cegelease business sold\\nDisclaimer: This press release is available in French and in English. In the event of any difference between the two versions, the original French version takes precedence. This press release may contain inside information. It was sent to Cegedim's authorized distributor on January 29, 2017, no earlier than 5:45 pm Paris time.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(texts[2][1], '\\n')\n",
    "texts[2][2][:616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe5915c-5fc2-4aeb-a052-d41e94975c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ef0c9db12c49979cd59c9ed1f30cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = retriever.model.encode([text_en])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a588b2b3-9d3d-4a0b-8e05-cc0c673a8f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = retriever.index.query(vector=query, top_k=3, include_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c1f01b-09e7-46b2-b209-87ddb8dd46ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news-64230', 0.651945531),\n",
       " ('news-68315', 0.617973),\n",
       " ('news-29373', 0.615841448)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(r['id'], r['score']) for r in results['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30d55176-da2b-4971-9678-5bab5ab434f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c5838f8-26b5-483e-bb86-64afa21a7de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4508b2344f9c4e15a9644d0d51c29f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45df29245d2f418da5bdbc8ff3feb7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6778])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = retriever.model.encode([text_en])[0].tolist()\n",
    "doc = 'Cloudera: Release of Full-Year 2019 Revenue'\n",
    "doc = \"Press Release Full year Financial Information at December 31, 2017\\nIFRS - Regulated Information - Not Audited\\nCloudera: organic growth accelerated in 2017\\nRevenues grew 5.9% like for like over the full year Outlook for consolidated 2017 EBITDA raised significantly Cloudera business sold\\nDisclaimer: This press release is available in French and in English. In the event of any difference between the two versions, the original French version takes precedence. This press release may contain inside information. It was sent to Cloudera's authorized distributor on January 29, 2017, no earlier than 5:45 pm Paris time.\"\n",
    "doc = retriever.model.encode([doc])[0].tolist()\n",
    "# t1 = torch.tensor([results['matches'][0]['values']])\n",
    "t1 = torch.tensor([doc])\n",
    "t2 = torch.tensor([query])\n",
    "F.cosine_similarity(t1, t2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
