{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb20be42-9b0f-40d1-9f71-6ecceb3ee07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os, sys\n",
    "import logging\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233408c0-08cb-4c25-a2f9-96ba8c6c7935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# MODEL = '/home/cdsw/models/self_rag_critic'\n",
    "# MODEL = '/home/cdsw/models/selfrag_llama2_7b'\n",
    "MODEL = '/home/cdsw/models/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, model_max_length=8192)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5cc9b5-bd89-4c76-b740-f07dc5633cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad927589b0048deb80f60135886324d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=True, # False when training\n",
    "    # do_sample=True,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878e400f-2550-4abe-bbf0-036eeb55ca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"do_sample\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 4096,\n",
       "  \"pad_token_id\": 2,\n",
       "  \"temperature\": 0.6,\n",
       "  \"top_p\": 0.9\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_config = model.generation_config\n",
    "gen_config.pad_token_id=tokenizer.eos_token_id\n",
    "gen_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3595275b-e353-48bd-bf58-839648f36476",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"context\": (\n",
    "        \"Given an instruction, please make a judgment on whether finding some external documents from the web (e.g., Wikipedia) helps to generate a better response. Please answer [Yes] or [No] and write an explanation.\\n\\n\"\n",
    "        \"##\\nInstruction: Give three tips for staying healthy.\\n\"\n",
    "        \"Need retrieval?: [Yes]\\n\"\n",
    "        \"Explanation: There might be some online sources listing three tips for staying healthy or some reliable sources to explain the effects of different behaviors on health. So retrieving documents is helpful to improve the response to this query.\\n\\n\"\n",
    "        \"##\\nInstruction: Describe a time when you had to make a difficult decision.\\n\"\n",
    "        \"Need retrieval?: [No]\\n\"\n",
    "        \"Explanation: This instruction is asking about some personal experience and thus it does not require one to find some external documents.\\n\\n\"\n",
    "        \"##\\nInstruction: Write a short story in third person narration about a protagonist who has to make an important career decision.\\n\"\n",
    "        \"Need retrieval?: [No]\\n\"\n",
    "        \"Explanation: This instruction asks us to write a short story, which does not require external evidence to verify.\\n\\n\"\n",
    "        \"##\\nInstruction: What is the capital of France?\\n\"\n",
    "        \"Need retrieval?: [Yes]\\n\"\n",
    "        \"Explanation: While the instruction simply asks us to answer the capital of France, which is a widely known fact, retrieving web documents for this question can still help.\\n\\n\"\n",
    "        \"##\\n Instruction: Find the area of a circle given its radius. Radius = 4\\n\"\n",
    "        \"Need retrieval?: [No]\\n\"\n",
    "        \"Explanation: This is a math question and although we may be able to find some documents describing a formula, it is unlikely to find a document exactly mentioning the answer.\\n\\n\"\n",
    "        \"##\\nInstruction: Arrange the words in the given sentence to form a grammatically correct sentence. quickly the brown fox jumped\\n\"\n",
    "        \"Need retrieval?: [No]\\n\"\n",
    "        \"Explanation: This task doesn't require any external evidence, as it is a simple grammatical question.\\n\\n\"\n",
    "        \"##\\nInstruction: Explain the process of cellular respiration in plants.\"\n",
    "        \"Need retrieval?: [Yes]\\n\"\n",
    "        \"Explanation: This instruction asks for a detailed description of a scientific concept, and is highly likely that we can find a reliable and useful document to support the response.\\n\\n\"\n",
    "        \"##\\nInstruction:{instruction}\\n\"\n",
    "        \"Need retrieval?: \"\n",
    "    ),\n",
    "    \"multi_retrieval\": (\n",
    "        \"You will be provided with an instruction, evidence, output sentence, and preceding sentences (optional). If the preceding sentence is given, the output should be the sentence that follows those preceding sentences.  Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. If the output sentence can be verified solely with the evidence or doesn’t require any verification, respond with [No Retrieval]. If additional information is needed to verify the output sentence, respond with [Retrieval]. Please provide explanations for your judgments.\\n\\n\"\n",
    "        \"##\\nInstruction: Explain the use of word embeddings in Natural Language Processing.\\n\"\n",
    "        \"Preceding sentences: Word embeddings are one of the most powerful tools available for Natural Language Processing (NLP). They are mathematical representations of words or phrases in a vector space, allowing similarities between words and the context in which they are used to be measured.\\n\"\n",
    "        \"Evidence: Word embedding\\nWord embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension.\\n\"\n",
    "        \"Output: Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.\\n\"\n",
    "        \"Rating: [Retrieval]\\n\"\n",
    "        \"Explanation: The output discusses the applications of word embeddings, while the evidence only discusses the definitions of word embeddings and how it works. Therefore, we need to retrieve other evidence to verify whether the output is actually correct or not.\\n\"\n",
    "        \"###\\nInstruction: {instruction}\\n\"\n",
    "        \"Preceding sentences: {preceding_sentences}\\n\"\n",
    "        \"Evidence: {evidence}\\n\"\n",
    "        \"Output: {target_output}\\n\"\n",
    "        \"Rating: \"),\n",
    "    \"multi_retrieval_no_preceding\": (\n",
    "        \"You will be provided with an instruction, evidence, output sentence, and preceding sentences (optional). If the preceding sentence is given, the output should be the sentence that follows those preceding sentences.  Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. If the output sentence can be verified solely with the evidence or doesn’t require any verification, respond with [No Retrieval]. If additional information is needed to verify the output sentence, respond with [Retrieval]. Please provide explanations for your judgments.\\n\"\n",
    "        \"\\n##\\nInstruction: Explain the use of word embeddings in Natural Language Processing.\\n\"\n",
    "        \"Evidence: Word embedding\\nWord embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension.\\n\"\n",
    "        \"Output: Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.\\n\"\n",
    "        \"Rating: [Retrieval]\\n\"\n",
    "        \"Explanation: The output discusses the applications of word embeddings, while the evidence only discusses the definitions of word embeddings and how it works. Therefore, we need to retrieve other evidence to verify whether the output is actually correct or not.\\n\"\n",
    "        \"\\n##\\nInstruction: {instruction}\\n\"\n",
    "        \"Evidence: {evidence}\\n\"\n",
    "        \"Output: {target_output}\\n\"\n",
    "        \"Rating: \"\n",
    "    ),\n",
    "    \"multi_retrieval_three_way\": (\n",
    "        \"You will be provided with an instruction, evidence, output sentence, and preceding sentences (optional). If the preceding sentence is given, the output should be the sentence that follows those preceding sentences.  Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. There are three cases:\\n\"\n",
    "        \"- If the output sentence can be verified solely with the evidence, then respond with [Continue to Use Evidence]. \\n\"\n",
    "        \"- If the sentence doesn't require any factual verification (e.g., a subjective sentence or a sentence about common sense), then respond with  [No Retrieval]. \\n\"\n",
    "        \"If additional information is needed to verify the output sentence, respond with [Retrieval]. Please provide explanations for your judgments. \\n\\n\"\n",
    "        \"##\\nInstruction: Explain the use of word embeddings in Natural Language Processing.\\n\"\n",
    "        \"Preceding sentences: Word embeddings are one of the most powerful tools available for Natural Language Processing (NLP). They are mathematical representations of words or phrases in a vector space, allowing similarities between words and the context in which they are used to be measured. \\n\"\n",
    "        \"Evidence:\\nWord embedding\\nWord embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension. \\n\"\n",
    "        \"Output: Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.\\n\"\n",
    "        \"Rating: [Retrieval]\\n\"\n",
    "        \"Explanation: The output discusses the applications of word embeddings, while the evidence only discusses the definitions of word embeddings and how it works. Therefore, we need to retrieve other evidence to verify whether the output is correct or not.\\n\"\n",
    "        \"###\\nInstruction: {instruction}\\n\"\n",
    "        \"Preceding sentences: {preceding_sentences}\\n\"\n",
    "        \"Evidence: {evidence}\\n\"\n",
    "        \"Output: {target_output}\\n\"\n",
    "        \"Rating: \"\n",
    "    ),\n",
    "    \"multi_retrieval_three_way_no_preceding\": (\n",
    "        \"You will be provided with an instruction, evidence, output sentence, and preceding sentences (optional). If the preceding sentence is given, the output should be the sentence that follows those preceding sentences.  Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. There are three cases:\\n\"\n",
    "        \"- If the output sentence can be verified solely with the evidence, then respond with [Continue to Use Evidence]. \\n\"\n",
    "        \"- If the sentence doesn't require any factual verification (e.g., a subjective sentence or a sentence about common sense), then respond with  [No Retrieval]. \\n\"\n",
    "        \"- If additional information is needed to verify the output sentence, respond with [Retrieval]. Please provide explanations for your judgments. \\n\\n\"\n",
    "        \"##\\nInstruction: Explain the use of word embeddings in Natural Language Processing.\\n\"\n",
    "        \"Preceding sentences: Word embeddings are one of the most powerful tools available for Natural Language Processing (NLP). They are mathematical representations of words or phrases in a vector space, allowing similarities between words and the context in which they are used to be measured. \\n\"\n",
    "        \"Evidence:\\nWord embedding\\nWord embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension. \\n\"\n",
    "        \"Output: Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.\\n\"\n",
    "        \"Rating: [Retrieval]\\n\"\n",
    "        \"Explanation: The output discusses the applications of word embeddings, while the evidence only discusses the definitions of word embeddings and how it works. Therefore, we need to retrieve other evidence to verify whether the output is correct or not.\\n\"\n",
    "        \"###\\nInstruction: {instruction}\\n\"\n",
    "        \"Evidence: {evidence}\\n\"\n",
    "        \"Output: {target_output}\\n\"\n",
    "        \"Rating: \"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9277eac9-2774-45df-afca-55c32e789d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=200):\n",
    "    print(prompt)\n",
    "    print('\\nTokenizing ...\\n')\n",
    "    input_ids = tokenizer([prompt], return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "    print('Start inference:', str(datetime.now()))\n",
    "    _ = model.generate(\n",
    "        **input_ids,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        # top_p=0.9,\n",
    "        # temperature=0.1,\n",
    "        # early_stopping=True,\n",
    "        generation_config=gen_config,\n",
    "    )\n",
    "    print('Completed:', str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57352be-b510-4a5d-9d54-e5825c6b1501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?'\n",
    "paragraph = '''What's new in Cloudera Runtime 7.1.9\n",
    "Understand the functionalities and improvements to features of components in Cloudera Runtime 7.1.9.\n",
    "Open Data Lakehouse, powered by Apache Iceberg\n",
    "CDP Private Cloud Base 7.1.9 delivers the hybrid Open Data Lakehouse providing the following benefits:\n",
    "Open architecture\n",
    "Cloudera’s Open Data Lakehouse, powered by Apache Iceberg is 100% open—open source, open standards based, and with wide community adoption. It can store multiple data formats and enables multiple engines to work on the same data.\n",
    "Ease of adoption\n",
    "By integrating Iceberg right into the Shared Data Experience (SDX) and Apache Ozone, Cloudera offers the easiest path to deploying a lakehouse. Additional capabilities like schema evolution, hidden partition, and more simplify data management for large datasets.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad945901-c02f-4174-84b2-7ed7cd20e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an instruction, please make a judgment on whether finding some external documents from the web (e.g., Wikipedia) helps to generate a better response. Please answer [Yes] or [No] and write an explanation.\n",
      "\n",
      "##\n",
      "Instruction: Give three tips for staying healthy.\n",
      "Need retrieval?: [Yes]\n",
      "Explanation: There might be some online sources listing three tips for staying healthy or some reliable sources to explain the effects of different behaviors on health. So retrieving documents is helpful to improve the response to this query.\n",
      "\n",
      "##\n",
      "Instruction: Describe a time when you had to make a difficult decision.\n",
      "Need retrieval?: [No]\n",
      "Explanation: This instruction is asking about some personal experience and thus it does not require one to find some external documents.\n",
      "\n",
      "##\n",
      "Instruction: Write a short story in third person narration about a protagonist who has to make an important career decision.\n",
      "Need retrieval?: [No]\n",
      "Explanation: This instruction asks us to write a short story, which does not require external evidence to verify.\n",
      "\n",
      "##\n",
      "Instruction: What is the capital of France?\n",
      "Need retrieval?: [Yes]\n",
      "Explanation: While the instruction simply asks us to answer the capital of France, which is a widely known fact, retrieving web documents for this question can still help.\n",
      "\n",
      "##\n",
      " Instruction: Find the area of a circle given its radius. Radius = 4\n",
      "Need retrieval?: [No]\n",
      "Explanation: This is a math question and although we may be able to find some documents describing a formula, it is unlikely to find a document exactly mentioning the answer.\n",
      "\n",
      "##\n",
      "Instruction: Arrange the words in the given sentence to form a grammatically correct sentence. quickly the brown fox jumped\n",
      "Need retrieval?: [No]\n",
      "Explanation: This task doesn't require any external evidence, as it is a simple grammatical question.\n",
      "\n",
      "##\n",
      "Instruction: Explain the process of cellular respiration in plants.Need retrieval?: [Yes]\n",
      "Explanation: This instruction asks for a detailed description of a scientific concept, and is highly likely that we can find a reliable and useful document to support the response.\n",
      "\n",
      "##\n",
      "Instruction:What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?\n",
      "Need retrieval?: \n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-17 09:36:13.148250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Yes]\n",
      "Ex\n",
      "Completed: 2024-04-17 09:36:18.609312\n"
     ]
    }
   ],
   "source": [
    "prompt = PROMPT_DICT['context'].format_map({\n",
    "    'instruction': query\n",
    "})\n",
    "generate(prompt, max_new_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a59c0e-ec21-4d86-9252-69d5f3b7b393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Can you tell me the difference between llamas and alpacas?\",\n",
    "paragraph = \"The alpaca (Lama pacos) is a species of South American camelid mammal. It is similar to, and often confused with, the llama. Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eece67b-27b8-4c18-82a5-157a833f6769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be provided with an instruction, evidence, output sentence, and preceding sentences (optional). If the preceding sentence is given, the output should be the sentence that follows those preceding sentences.  Your task is to determine whether the information in the output sentence can be fully verified by the evidence or if it requires further external verification. If the output sentence can be verified solely with the evidence or doesn’t require any verification, respond with [No Retrieval]. If additional information is needed to verify the output sentence, respond with [Retrieval]. Please provide explanations for your judgments.\n",
      "\n",
      "##\n",
      "Instruction: Explain the use of word embeddings in Natural Language Processing.\n",
      "Evidence: Word embedding\n",
      "Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension.\n",
      "Output: Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.\n",
      "Rating: [Retrieval]\n",
      "Explanation: The output discusses the applications of word embeddings, while the evidence only discusses the definitions of word embeddings and how it works. Therefore, we need to retrieve other evidence to verify whether the output is actually correct or not.\n",
      "\n",
      "##\n",
      "Instruction: ('Can you tell me the difference between llamas and alpacas?',)\n",
      "Evidence: The alpaca (Lama pacos) is a species of South American camelid mammal. It is similar to, and often confused with, the llama. Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.\n",
      "Output: The main difference between Cloudera CDP Base 7.1.7 and 7.1.9 is the inclusion of Apache Iceberg in the 7.1.9 release.\n",
      "Rating: \n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-17 10:07:09.072697\n",
      ".[Utility:5]</s>\n",
      "Completed: 2024-04-17 10:07:11.861384\n"
     ]
    }
   ],
   "source": [
    "prompt = PROMPT_DICT['multi_retrieval_no_preceding'].format_map({\n",
    "    'instruction': query,\n",
    "    'evidence': paragraph,\n",
    "    'target_output': 'The main difference between Cloudera CDP Base 7.1.7 and 7.1.9 is the inclusion of Apache Iceberg in the 7.1.9 release.'\n",
    "})\n",
    "generate(prompt, max_new_tokens=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
