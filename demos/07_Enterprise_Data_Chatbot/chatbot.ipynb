{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193b70ff-f061-479c-a156-77463406adc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os, sys\n",
    "import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# log = logging.getLogger(os.path.basename(__file__))\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, BitsAndBytesConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pyarrow.parquet as pq\n",
    "from pinecone import Pinecone, PodSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72a581-5d43-4796-9415-67025eccde57",
   "metadata": {},
   "source": [
    "### Lab on Milestone 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c965730a-1058-4387-b77d-2105bf5b2b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/train-1-of-2.parquet'\n",
    "\n",
    "PINECONE_API_KEY = \"4eb3035e-8ef3-41cb-b108-28b8b7e250b9\"\n",
    "PINECONE_INDEX_NAME = \"rag4fin\"\n",
    "\n",
    "GEN_MODEL = '/home/cdsw/models/Mistral-7B-Instruct-v0.2'\n",
    "EMB_MODEL = '/home/cdsw/models/all-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92141a5b-9856-4def-a355-822d5f72fd7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL, model_max_length=8192)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c556ce-5010-4615-93ed-3f66af19e3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s>[INST] I'd like to show off how chat templating works! [/INST]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = [\n",
    "  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "  {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
    "]\n",
    "\n",
    "tokenizer.apply_chat_template(chat, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57f0c0-908f-45ce-bf9e-48ef56d8972b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    GEN_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=True, # False when training\n",
    "    # do_sample=True,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9ef8d4-d434-4444-bc61-6cb6e366c68e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"pad_token_id\": 2\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_config = gen_model.generation_config\n",
    "gen_config.pad_token_id=tokenizer.eos_token_id\n",
    "gen_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39920c7a-8d57-488f-9066-e8b033f2e34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        logging.info('Loading embedding model %s ... ' % EMB_MODEL)\n",
    "        self.model = SentenceTransformer(EMB_MODEL)\n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        self.index = pc.Index(PINECONE_INDEX_NAME)\n",
    "        # self.texts = self.load_texts()\n",
    "        self.df = pq.read_table(DATA_FILE).to_pandas()\n",
    "\n",
    "    # def load_texts(self):\n",
    "    #     with open(DATA_FILE) as f:\n",
    "    #         lines = f.read().split('\\n')\n",
    "    #     return lines\n",
    "\n",
    "    def text_id(self, user_input, top_k=3):\n",
    "        query = self.model.encode([user_input])[0].tolist()\n",
    "        results = self.index.query(vector=query, top_k=top_k, include_values=True)['matches']\n",
    "        return [int(r['id'].split('-')[1]) for r in results]\n",
    "\n",
    "    def get_texts(self, user_input, top_k=3):\n",
    "        text_ids = self.text_id(user_input, top_k)\n",
    "        titles, texts = self.df['title'], self.df['text']\n",
    "        return [(id, titles[id], texts[id]) for id in text_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0718b088-75e2-49c2-80ff-a3fcac7249e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRIEF-Bigger Capital Fund Reports An 8 Pct Pas...</td>\n",
       "      <td>January 2, 2018 / 9:31 PM / Updated 8 minutes ...</td>\n",
       "      <td>https://www.reuters.com/article/brief-bigger-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Markets: Asia shares reach decade top o...</td>\n",
       "      <td>NEW YORK (Reuters) - European stocks closed lo...</td>\n",
       "      <td>https://in.reuters.com/article/global-markets/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is the only person in Washington ...</td>\n",
       "      <td>Fears of a government shutdown coursed through...</td>\n",
       "      <td>https://www.cnbc.com/2018/01/18/donald-trump-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actor Casey Affleck withdraws as 2018 Oscar pr...</td>\n",
       "      <td>03 PM / Updated 19 minutes ago Actor Casey Af...</td>\n",
       "      <td>https://www.reuters.com/article/us-oscars-case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU mulls new link between budget and civic rights</td>\n",
       "      <td>January 22, 2018 / 7:23 PM / Updated 2 hours a...</td>\n",
       "      <td>https://uk.reuters.com/article/uk-eu-poland-bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153116</th>\n",
       "      <td>Billie Jean King: International Women's Day sh...</td>\n",
       "      <td>Following the widespread adoption of the \"Me T...</td>\n",
       "      <td>https://www.cnbc.com/2018/03/08/billie-jean-ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153117</th>\n",
       "      <td>Lamb Weston Announces Details of Fiscal 2018 T...</td>\n",
       "      <td>EAGLE, Idaho--(BUSINESS WIRE)-- Lamb Weston Ho...</td>\n",
       "      <td>http://www.cnbc.com/2018/03/16/business-wire-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153118</th>\n",
       "      <td>China says political education for students no...</td>\n",
       "      <td>March 16, 2018 / 5:03 AM / Updated 2 hours ago...</td>\n",
       "      <td>https://uk.reuters.com/article/uk-china-parlia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153119</th>\n",
       "      <td>Blue Cross, Lyft, Walgreens and CVS partner to...</td>\n",
       "      <td>Blue Cross, Lyft, Walgreens and CVS partner to...</td>\n",
       "      <td>https://www.cnbc.com/2018/03/14/blue-cross-lyf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153120</th>\n",
       "      <td>Britain's Johnson says Northern Irish border i...</td>\n",
       "      <td>LONDON, Feb 28 (Reuters) - The issue of Northe...</td>\n",
       "      <td>https://www.reuters.com/article/britain-eu-nir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0       BRIEF-Bigger Capital Fund Reports An 8 Pct Pas...   \n",
       "1       Global Markets: Asia shares reach decade top o...   \n",
       "2       Donald Trump is the only person in Washington ...   \n",
       "3       Actor Casey Affleck withdraws as 2018 Oscar pr...   \n",
       "4       EU mulls new link between budget and civic rights   \n",
       "...                                                   ...   \n",
       "153116  Billie Jean King: International Women's Day sh...   \n",
       "153117  Lamb Weston Announces Details of Fiscal 2018 T...   \n",
       "153118  China says political education for students no...   \n",
       "153119  Blue Cross, Lyft, Walgreens and CVS partner to...   \n",
       "153120  Britain's Johnson says Northern Irish border i...   \n",
       "\n",
       "                                                     text  \\\n",
       "0       January 2, 2018 / 9:31 PM / Updated 8 minutes ...   \n",
       "1       NEW YORK (Reuters) - European stocks closed lo...   \n",
       "2       Fears of a government shutdown coursed through...   \n",
       "3        03 PM / Updated 19 minutes ago Actor Casey Af...   \n",
       "4       January 22, 2018 / 7:23 PM / Updated 2 hours a...   \n",
       "...                                                   ...   \n",
       "153116  Following the widespread adoption of the \"Me T...   \n",
       "153117  EAGLE, Idaho--(BUSINESS WIRE)-- Lamb Weston Ho...   \n",
       "153118  March 16, 2018 / 5:03 AM / Updated 2 hours ago...   \n",
       "153119  Blue Cross, Lyft, Walgreens and CVS partner to...   \n",
       "153120  LONDON, Feb 28 (Reuters) - The issue of Northe...   \n",
       "\n",
       "                                                      url  \n",
       "0       https://www.reuters.com/article/brief-bigger-c...  \n",
       "1       https://in.reuters.com/article/global-markets/...  \n",
       "2       https://www.cnbc.com/2018/01/18/donald-trump-t...  \n",
       "3       https://www.reuters.com/article/us-oscars-case...  \n",
       "4       https://uk.reuters.com/article/uk-eu-poland-bu...  \n",
       "...                                                   ...  \n",
       "153116  https://www.cnbc.com/2018/03/08/billie-jean-ki...  \n",
       "153117  http://www.cnbc.com/2018/03/16/business-wire-l...  \n",
       "153118  https://uk.reuters.com/article/uk-china-parlia...  \n",
       "153119  https://www.cnbc.com/2018/03/14/blue-cross-lyf...  \n",
       "153120  https://www.reuters.com/article/britain-eu-nir...  \n",
       "\n",
       "[153121 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = Retriever()\n",
    "retriever.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8dae87-3563-459e-b8c0-931a49892c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66310 Microsoft beats on bottom line\n",
      "Microsoft beats on bottom line 1 Hour Ago 02:26 02:26 | 8 Hrs Ago 03:14 03:14 | 10:36 AM ET Tue, 30 \n",
      "==============================\n",
      "83809 Microsoft Second Quarter Earnings: Xbox, Cortana, and Aquisitions | Fortune\n",
      "By Jonathan Vanian 8:54 PM EST \n",
      "Microsoft’s latest quarterly sales results beat Wall Street’s expect\n",
      "==============================\n",
      "97787 BRIEF-CI Games Prelim FY Revenue At About 100.5 Million Zlotys\n",
      "Feb 16 (Reuters) - CI GAMES SA:\n",
      "* PRELIM FY REVENUE AT ABOUT 100.5 MILLION ZLOTYS Source text for Ei\n",
      "==============================\n",
      "75550 Microsoft reports better-than-expected quarterly revenue, profit\n",
      "January 31, 2018 / 9:19 PM / Updated 21 minutes ago Microsoft's cloud computing business grows, stoc\n",
      "==============================\n",
      "85162 BRIEF-Gold Town Games January Net Revenue SEK 1.3 Mln\n",
      "Feb 19 (Reuters) - Gold Town Games Ab:\n",
      "* NET REVENUE IN JANUARY AT SEK 1.3 MILLION Source text for E\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the revenue of Microsoft in game?'\n",
    "texts = retriever.get_texts(query, top_k=5)\n",
    "\n",
    "for id, title, text in texts:\n",
    "    print(id, title)\n",
    "    print(text[:100])\n",
    "    print('=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b60573-8f56-4e7d-aab5-56fe12b9b46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = '%s\\n%s Please answer with no more than 100 words.'\n",
    "id, title, text = texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb191ce7-37da-427b-88bb-03155b4b6eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ...\n",
      "Start inference: 2024-04-14 09:43:48.169931\n",
      "Microsoft's gaming revenue comes primarily from the sales of its Xbox consoles and games, as well as from its subscription service, Xbox Live. In the most recent quarter, gaming revenue was $3.2 billion, up 32% year over year. This growth was driven by strong sales of Xbox One consoles and the continued growth of Xbox Live subscriptions.</s>\n",
      "Completed: 2024-04-14 09:43:54.371825\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template % (text, query)\n",
    "\n",
    "print('Tokenizing ...')\n",
    "input_ids = tokenizer([prompt], return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "print('Start inference:', str(datetime.now()))\n",
    "_ = gen_model.generate(\n",
    "    **input_ids,\n",
    "    streamer=streamer,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    "    # top_p=0.9,\n",
    "    # temperature=0.1,\n",
    "    # early_stopping=True,\n",
    "    generation_config=gen_config,\n",
    ")\n",
    "print('Completed:', str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda82006-d848-4f35-8aa9-7b8122a6e914",
   "metadata": {},
   "source": [
    "#### Stop criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17dbc1af-68e7-435e-8c13-52f880a37a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90569 Nvidia’s Cryptic Road Ahead\n",
      "0 COMMENTS Nvidia NVDA 6.69% may have only high-quality problems these days, but it still needs to s\n",
      "==============================\n",
      "37761 Nvidia rallies on driverless car partnership announcement\n",
      "Nvidia rallies on driverless car partnership announcement 4 Hours Ago The \"Squawk on the Street\" cre\n",
      "==============================\n",
      "10590 Why Ethereum's Price Is Still a Boon for Nvidia and AMD | Fortune\n",
      "Ethereum How Ethereum Is Boosting Nvidia and AMD Sebastian Kastner, lead engineer at HydroMiner GmbH\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "query = 'What do you think about Microsoft and Nvidia?'\n",
    "texts = retriever.get_texts(query, top_k=3)\n",
    "\n",
    "for id, title, text in texts:\n",
    "    print(id, title)\n",
    "    print(text[:100])\n",
    "    print('=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522cfb59-820d-4bc2-a039-832e7c3a5834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rency mining. Higher GPU prices also lower profitability for miners. \n",
      "“We are raising estimates meaningfully for both graphics vendors, but sustainability is a long-term issue especially for AMD,” Morgan Stanley analysts wrote Tuesday. \n",
      "Ethereum prices were relatively flat at $1,000 while Bitcoin rose to $11,200, up 4%, on Tuesday. Ethereum rose close to $1,400 earlier this year. SPONSORED FINANCIAL CONTENT \n",
      "What do you think about Microsoft and Nvidia? Please answer with no more than 150 words.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = '%s\\n%s Please answer with no more than 150 words.'\n",
    "text = '\\n'.join([text for _, _, text in texts])\n",
    "prompt = prompt_template % (text, query)\n",
    "print(prompt[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3004b752-f615-47a1-bbda-321a6be27a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL, model_max_length=8192)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac7f0b1-2550-4b45-b0a4-81522061823f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList\n",
    "\n",
    "class EosLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self):\n",
    "        self.stop_rate = None\n",
    "        self.newline_id = 13\n",
    "        \n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        eos = tokenizer.eos_token_id\n",
    "        if scores[0].argmax().item() != self.newline_id and self.stop_rate is None:\n",
    "            self.stop_rate = 1.0\n",
    "        if self.stop_rate is not None:\n",
    "            if scores[0].argmax().item() == self.newline_id:\n",
    "                self.stop_rate *= 1.1\n",
    "            scores[:, eos] = scores[:, eos] * self.stop_rate\n",
    "\n",
    "        # values, indexes = scores.topk(3)\n",
    "        # for val, idx in zip(values.view(-1), indexes.view(-1)):\n",
    "        #     tok = tokenizer.convert_ids_to_tokens(idx.item())\n",
    "        #     logit = val.item()\n",
    "        #     print('%s(%s)' % (tok, logit), end=' ')\n",
    "        # print(scores[0, eos], self.stop_rate)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "logits_processor = LogitsProcessorList()\n",
    "logits_processor.append(EosLogitsProcessor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2906f831-fbf4-43a4-a7c0-84107afee1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Microsoft and Nvidia have a long-standing partnership, with Microsoft using Nvidia GPUs in its Azure cloud platform and Nvidia using Microsoft’s Azure for its own AI research. The partnership was further strengthened in 2017 when Microsoft announced that it would be using Nvidia GPUs in its new data centers, and Nvidia announced that it would be using Microsoft’s Azure for its own AI research. The partnership is expected to continue to grow in the future, with both companies investing in AI and machine learning technologies. Microsoft and Nvidia are also working together on autonomous vehicles, with Nvidia providing the AI computing platform and Microsoft providing the mapping and location data. The partnership is a win-win for both companies, with Microsoft gaining access to Nvidia’s advanced GPUs and Nvidia gaining access to Microsoft’s vast data and cloud resources.</s>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "_ = gen_model.generate(\n",
    "    input_ids,\n",
    "    streamer=streamer,\n",
    "    logits_processor=logits_processor,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "# outputs = gen_model.generate(\n",
    "#     input_ids,\n",
    "#     logits_processor=logits_processor,\n",
    "#     max_new_tokens=200,\n",
    "#     do_sample=False,\n",
    "# )\n",
    "# res = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b042ee6-84bb-4c8e-9352-4f7c71235455",
   "metadata": {},
   "source": [
    "### Lab on Milestone 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da6f138-1afe-41a5-bfbc-6d98010f4a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "CHAT_MODEL = '/home/cdsw/models/selfrag_llama2_7b'\n",
    "EMB_MODEL = '/home/cdsw/models/contriever-msmarco'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9cb26-71e7-41dc-a028-b25f6b364106",
   "metadata": {},
   "source": [
    "#### Facebook Contriever and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ee3a9f-337d-47d8-bdcc-a544f73574d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(EMB_MODEL)\n",
    "model = AutoModel.from_pretrained(EMB_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a936e55-5c25-483c-8390-02ba20b778e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertModel,\n",
       " BertModel(\n",
       "   (embeddings): BertEmbeddings(\n",
       "     (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "     (position_embeddings): Embedding(512, 768)\n",
       "     (token_type_embeddings): Embedding(2, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): BertEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0-11): 12 x BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): BertPooler(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (activation): Tanh()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer), type(model), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d29d31b-3e2b-460d-96ef-7695c5c4af50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Where was Marie Curie born?\",\n",
    "    \"Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.\",\n",
    "    \"Born in Paris on 15 May 1859, Pierre Curie was the son of Eugène Curie, a doctor of French Catholic origin from Alsace.\"\n",
    "]\n",
    "\n",
    "# Apply tokenizer\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff7c89a-80ea-4d21-95e8-047cbd242983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1066,  0.0164,  0.0547,  ..., -0.0065, -0.0631, -0.0280],\n",
       "         [ 0.0192, -0.0602,  0.0502,  ...,  0.1185, -0.0204, -0.0111],\n",
       "         [ 0.1103, -0.0207,  0.0044,  ...,  0.0599, -0.0432,  0.0183],\n",
       "         ...,\n",
       "         [ 0.0305, -0.2994, -0.0895,  ...,  0.2829,  0.0329,  0.0951],\n",
       "         [ 0.0298, -0.3350, -0.0862,  ...,  0.2983,  0.0351,  0.0803],\n",
       "         [ 0.0299, -0.2928, -0.0951,  ...,  0.2991,  0.0265,  0.0623]],\n",
       "\n",
       "        [[ 0.0799,  0.0201,  0.0418,  ...,  0.0752,  0.0130,  0.0336],\n",
       "         [-0.0250,  0.0173,  0.0594,  ...,  0.1173, -0.1175,  0.0543],\n",
       "         [ 0.0280,  0.0259, -0.0916,  ..., -0.1142, -0.0608,  0.1254],\n",
       "         ...,\n",
       "         [ 0.0315, -0.1623, -0.0734,  ...,  0.1735, -0.0453,  0.0775],\n",
       "         [ 0.0674, -0.1745, -0.0764,  ...,  0.1819, -0.0478,  0.0687],\n",
       "         [ 0.0397, -0.1430, -0.0823,  ...,  0.1684, -0.0414,  0.0401]],\n",
       "\n",
       "        [[ 0.0364, -0.0647,  0.0651,  ...,  0.0903,  0.0586,  0.0269],\n",
       "         [-0.0173,  0.2125,  0.0231,  ..., -0.0572,  0.0988, -0.2662],\n",
       "         [-0.0478, -0.1174, -0.1090,  ...,  0.0656,  0.0384, -0.0421],\n",
       "         ...,\n",
       "         [ 0.0904,  0.0055, -0.0863,  ...,  0.0272, -0.0274,  0.0982],\n",
       "         [-0.1369, -0.0950,  0.0118,  ..., -0.0915, -0.0675, -0.0088],\n",
       "         [-0.0762, -0.0748, -0.0086,  ...,  0.0026, -0.0144, -0.0229]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0135, -0.0092,  0.0013,  ...,  0.0288,  0.0191, -0.0925],\n",
       "        [ 0.0191, -0.0188, -0.0401,  ...,  0.0127, -0.0204, -0.0245],\n",
       "        [ 0.0534, -0.0158, -0.1317,  ..., -0.0812, -0.0167, -0.0901]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "013ee897-dc2a-4483-98b2-821baa05e3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 30, 1]),\n",
       " tensor([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = inputs['attention_mask']\n",
    "# type(mask), mask, ~mask[..., None]\n",
    "mask[..., None].shape, mask[..., None][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586bc025-d816-49b0-a578-04929fda488b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean pooling\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98240e64-14c8-4980-b97c-ed559671c532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0161,  0.0055,  0.0199,  ...,  0.0372, -0.0831, -0.0112],\n",
       "        [ 0.0037,  0.0346, -0.0131,  ...,  0.0247, -0.1021, -0.0303],\n",
       "        [-0.0146, -0.0235, -0.0338,  ...,  0.0277, -0.0025, -0.0092]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a7985-22e6-4de0-85da-f223af91fe15",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500b4026-4a27-49ed-9746-3e42e1468400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_prompt(input, paragraph=None):\n",
    "    prompt = \"### Instruction:\\n{0}\\n\\n### Response:\\n\".format(input)\n",
    "    if paragraph is not None:\n",
    "        prompt += \"[Retrieval]<paragraph>{0}</paragraph>\".format(paragraph)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d22db3f-9a63-46aa-a9f3-d91d8c135ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Leave odd one out: twitter, instagram, whatsapp.\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Leave odd one out: twitter, instagram, whatsapp.\",\n",
    "    \"Can you tell me the difference between llamas and alpacas?\"\n",
    "]\n",
    "\n",
    "prompt = format_prompt(queries[0])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366e2924-44c8-447b-a375-ebfc136908fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CHAT_MODEL, model_max_length=8192)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec382ce-e533-4eb9-a90d-d7371aa881dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b758a3d9dcd4c559e738bc332c8376e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_model = AutoModelForCausalLM.from_pretrained(\n",
    "    CHAT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=True, # False when training\n",
    "    # do_sample=True,\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15dec5f5-6fa6-4fc3-ba1f-db897360fdd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"do_sample\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 4096,\n",
       "  \"pad_token_id\": 2,\n",
       "  \"temperature\": 0.6,\n",
       "  \"top_p\": 0.9\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_config = chat_model.generation_config\n",
    "chat_config.pad_token_id=tokenizer.eos_token_id\n",
    "chat_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "382617cf-14e0-4479-9825-8b2d19e9d552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ...\n",
      "Start inference: 2024-04-14 09:45:10.511304\n",
      "Sure![Retrieval]<paragraph>[Irrelevant]Here are some key differences between llamas and alpacas:\n",
      "\n",
      "1.Appearance:2.3.4.5.[Utility:5]</s>\n",
      "Completed: 2024-04-14 09:45:13.606554\n"
     ]
    }
   ],
   "source": [
    "prompt = format_prompt(queries[1])\n",
    "\n",
    "print('Tokenizing ...')\n",
    "input_ids = tokenizer([prompt], return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "print('Start inference:', str(datetime.now()))\n",
    "_ = chat_model.generate(\n",
    "    **input_ids,\n",
    "    streamer=streamer,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    "    # top_p=0.9,\n",
    "    # temperature=0.1,\n",
    "    # early_stopping=True,\n",
    "    generation_config=gen_config,\n",
    ")\n",
    "print('Completed:', str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006b45db-28e9-4790-a831-a40eebb36620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_with_paragraph(prompt, paragraph=None, max_new_tokens=200):\n",
    "    prompt = format_prompt(prompt, paragraph)\n",
    "    print(prompt)\n",
    "    print('\\nTokenizing ...\\n')\n",
    "    input_ids = tokenizer([prompt], return_tensors=\"pt\", truncation=True).to('cuda')\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "    print('Start inference:', str(datetime.now()))\n",
    "    _ = chat_model.generate(\n",
    "        **input_ids,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        # top_p=0.9,\n",
    "        # temperature=0.1,\n",
    "        # early_stopping=True,\n",
    "        generation_config=chat_config,\n",
    "    )\n",
    "    print('Completed:', str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb16950b-e3b5-47fe-b3e0-242723dc14e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Can you tell me the difference between llamas and alpacas?\n",
      "\n",
      "### Response:\n",
      "[Retrieval]<paragraph>The alpaca (Lama pacos) is a species of South American camelid mammal. It is similar to, and often confused with, the llama. Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.</paragraph>\n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-14 09:45:13.693801\n",
      "[Relevant]Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.[Fully supported][Utility:5]</s>\n",
      "Completed: 2024-04-14 09:45:17.029711\n"
     ]
    }
   ],
   "source": [
    "generate_with_paragraph(\n",
    "    \"Can you tell me the difference between llamas and alpacas?\",\n",
    "    \"The alpaca (Lama pacos) is a species of South American camelid mammal. It is similar to, and often confused with, the llama. Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96dfd700-9ee3-45ba-ae5a-564361deb9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Does Cloudera CDP Base 7.1.7 support the REPL command?\n",
      "\n",
      "### Response:\n",
      "[Retrieval]<paragraph>If you want to use REPL commands to replicate Hive ACID tables between CDP Private Cloud Base clusters, ensure that your source cluster is on CDP Private Cloud Base 7.1.8 or a higher version.</paragraph>\n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-14 09:45:17.034353\n",
      "[Relevant]Yes, Cloudera CDP Base 7.1.7 supports the REPL command.[No support / Contradictory][Utility:5]</s>\n",
      "Completed: 2024-04-14 09:45:19.391306\n"
     ]
    }
   ],
   "source": [
    "generate_with_paragraph(\n",
    "    'Does Cloudera CDP Base 7.1.7 support the REPL command?',\n",
    "    'If you want to use REPL commands to replicate Hive ACID tables between CDP Private Cloud Base clusters, ensure that your source cluster is on CDP Private Cloud Base 7.1.8 or a higher version.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27516044-6e2d-420e-a07e-865e783f237d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-14 09:45:19.395783\n",
      "Here are some of the key differences:\n",
      "\n",
      "1.[Retrieval]<paragraph>[Irrelevant]This includes the Apache Hadoop framework, Apache Spark, Apache Kafka, and other open-source technologies.\n",
      "\n",
      "2.3.[Utility:5]</s>\n",
      "Completed: 2024-04-14 09:45:22.770310\n"
     ]
    }
   ],
   "source": [
    "generate_with_paragraph(\n",
    "    'What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35dc539d-62c6-4e5e-95f3-e1af51d4b18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?'\n",
    "paragraph = '''What's new in Cloudera Runtime 7.1.9\n",
    "Understand the functionalities and improvements to features of components in Cloudera Runtime 7.1.9.\n",
    "Open Data Lakehouse, powered by Apache Iceberg\n",
    "CDP Private Cloud Base 7.1.9 delivers the hybrid Open Data Lakehouse providing the following benefits:\n",
    "Open architecture\n",
    "Cloudera’s Open Data Lakehouse, powered by Apache Iceberg is 100% open—open source, open standards based, and with wide community adoption. It can store multiple data formats and enables multiple engines to work on the same data.\n",
    "Ease of adoption\n",
    "By integrating Iceberg right into the Shared Data Experience (SDX) and Apache Ozone, Cloudera offers the easiest path to deploying a lakehouse. Additional capabilities like schema evolution, hidden partition, and more simplify data management for large datasets.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e6b15e-4e14-4825-ae55-78457b367201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "What is Jim Brown's occupation?\n",
      "\n",
      "### Response:\n",
      "[Retrieval]<paragraph>Jim Ed Brown  James Edward Brown (April 1, 1934 – June 11, 2015) was an American country singer-songwriter who achieved fame in the 1950s with his two sisters as a member of the Browns. He later had a successful solo career from 1965 to 1974, followed by a string of major duet hits with fellow country music vocalist Helen Cornelius, through 1981. Brown was also the host of the \"Country Music Greats Radio Show\", a syndicated country music program from Nashville, Tennessee.</paragraph>\n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-18 14:52:52.443217\n",
      "[Relevant]Jim Brown is a former professional American football player and current actor.[Fully supported][Utility:5]</s>\n",
      "Completed: 2024-04-18 14:52:54.647934\n"
     ]
    }
   ],
   "source": [
    "generate_with_paragraph(query, paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a561ad6-15a7-4eef-aeea-59c0a88d149e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is Jim Brown's occupation?\"\n",
    "paragraph = '''Jim Ed Brown  James Edward Brown (April 1, 1934 – June 11, 2015) was an American country singer-songwriter who achieved fame in the 1950s with his two sisters as a member of the Browns. He later had a successful solo career from 1965 to 1974, followed by a string of major duet hits with fellow country music vocalist Helen Cornelius, through 1981. Brown was also the host of the \"Country Music Greats Radio Show\", a syndicated country music program from Nashville, Tennessee.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ccb2dd-4b7d-4754-9df3-604378a84a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "What is the difference between Cloudera CDP Base 7.1.7 and 7.1.9?\n",
      "\n",
      "### Response:\n",
      "[Retrieval]<paragraph>What's new in Cloudera Runtime 7.1.9\n",
      "Understand the functionalities and improvements to features of components in Cloudera Runtime 7.1.9.\n",
      "Open Data Lakehouse, powered by Apache Iceberg\n",
      "CDP Private Cloud Base 7.1.9 delivers the hybrid Open Data Lakehouse providing the following benefits:\n",
      "Open architecture\n",
      "Cloudera’s Open Data Lakehouse, powered by Apache Iceberg is 100% open—open source, open standards based, and with wide community adoption. It can store multiple data formats and enables multiple engines to work on the same data.\n",
      "Ease of adoption\n",
      "By integrating Iceberg right into the Shared Data Experience (SDX) and Apache Ozone, Cloudera offers the easiest path to deploying a lakehouse. Additional capabilities like schema evolution, hidden partition, and more simplify data management for large datasets.</paragraph>\n",
      "\n",
      "Tokenizing ...\n",
      "\n",
      "Start inference: 2024-04-18 14:51:20.715863\n",
      "[Relevant]The main difference between Cloudera CDP Base 7.1.7 and 7.1.9 is the inclusion of Apache Iceberg in the 7.1.9 release.[No support / Contradictory][Continue to Use Evidence]Iceberg is a new open-source project from Cloudera that provides a data management layer for large-scale data lakes.[Continue to Use Evidence]It allows for flexible and efficient data management, including the ability to store multiple data formats and enable multiple engines to work on the same data.[Utility:5]</s>\n",
      "Completed: 2024-04-18 14:51:28.479951\n"
     ]
    }
   ],
   "source": [
    "generate_with_paragraph(query, paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
